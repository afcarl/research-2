{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ogrisel/.virtualenvs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = fashion_mnist.load_data()\n",
    "images_train, labels_train = data_train\n",
    "images_test, labels_test = data_test\n",
    "images_train = images_train.astype(np.float32) / 255.\n",
    "images_test = images_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if keras.backend.image_data_format() == 'channels_last':\n",
    "    image_shape = (28, 28, 1)\n",
    "else:\n",
    "    image_shape = (1, 28, 28)\n",
    "images_train = images_train.reshape((-1,) + image_shape)\n",
    "images_test = images_test.reshape((-1,) + image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 16)          1168      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 2,586\n",
      "Trainable params: 2,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "model = Sequential(layers=[\n",
    "    Conv2D(8, kernel_size=3, activation='relu', padding=\"same\",\n",
    "           input_shape=image_shape),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(8, kernel_size=3, activation='relu', padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(8, kernel_size=3, activation='relu', padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(16, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 5s 101us/step - loss: 0.6284 - acc: 0.7715 - val_loss: 0.4541 - val_acc: 0.8348\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.4360 - acc: 0.8440 - val_loss: 0.4426 - val_acc: 0.8368\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.3897 - acc: 0.8601 - val_loss: 0.4017 - val_acc: 0.8540\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.3630 - acc: 0.8706 - val_loss: 0.3552 - val_acc: 0.8670\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.3452 - acc: 0.8751 - val_loss: 0.3460 - val_acc: 0.8710\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.3295 - acc: 0.8819 - val_loss: 0.3327 - val_acc: 0.8772\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.3170 - acc: 0.8857 - val_loss: 0.3164 - val_acc: 0.8823\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.3080 - acc: 0.8876 - val_loss: 0.3161 - val_acc: 0.8835\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.3008 - acc: 0.8919 - val_loss: 0.3175 - val_acc: 0.8863\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.2953 - acc: 0.8942 - val_loss: 0.3255 - val_acc: 0.8837\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(images_train, labels_train,\n",
    "                    validation_split=0.1, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = keras.backend.get_session()\n",
    "# y_train = np.eye(10)[labels_train]\n",
    "\n",
    "# model.total_loss.eval(session=session, feed_dict={\n",
    "#     model.inputs[0]: images_train,\n",
    "#     model.targets[0]: y_train,\n",
    "#     model.sample_weights[0]: np.ones(images_train.shape[0]),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
